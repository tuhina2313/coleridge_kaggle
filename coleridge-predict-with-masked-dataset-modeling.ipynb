{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "illegal-mattress",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-06-19T14:45:13.475471Z",
     "iopub.status.busy": "2021-06-19T14:45:13.473000Z",
     "iopub.status.idle": "2021-06-19T14:46:45.548749Z",
     "shell.execute_reply": "2021-06-19T14:46:45.547994Z",
     "shell.execute_reply.started": "2021-06-19T14:37:38.704101Z"
    },
    "papermill": {
     "duration": 92.112025,
     "end_time": "2021-06-19T14:46:45.548956",
     "exception": false,
     "start_time": "2021-06-19T14:45:13.436931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/coleridge-packages/packages/datasets\r\n",
      "Processing /kaggle/input/coleridge-packages/packages/datasets/datasets-1.5.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.19.5)\r\n",
      "Processing /kaggle/input/coleridge-packages/packages/datasets/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (3.4.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.11.1)\r\n",
      "Processing /kaggle/input/coleridge-packages/packages/datasets/tqdm-4.49.0-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.3)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from datasets) (0.8.5)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.2.2)\r\n",
      "Processing /kaggle/input/coleridge-packages/packages/datasets/huggingface_hub-0.0.7-py3-none-any.whl\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.25.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.3)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.0.4)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.7.4.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\r\n",
      "Installing collected packages: tqdm, xxhash, huggingface-hub, datasets\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.56.2\r\n",
      "    Uninstalling tqdm-4.56.2:\r\n",
      "      Successfully uninstalled tqdm-4.56.2\r\n",
      "Successfully installed datasets-1.5.0 huggingface-hub-0.0.7 tqdm-4.49.0 xxhash-2.0.0\r\n",
      "Processing /kaggle/input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval==1.2.2) (1.19.5)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval==1.2.2) (0.24.1)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.0.1)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (1.5.4)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval==1.2.2) (2.1.0)\r\n",
      "Installing collected packages: seqeval\r\n",
      "Successfully installed seqeval-1.2.2\r\n",
      "Processing /kaggle/input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\r\n",
      "tokenizers is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Processing /kaggle/input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (2020.11.13)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (20.9)\r\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (0.10.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (1.19.5)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (2.25.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (3.0.12)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (0.0.43)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.5.0.dev0) (4.49.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.5.0.dev0) (3.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.5.0.dev0) (3.7.4.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.5.0.dev0) (2.4.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (2020.12.5)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (1.26.3)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.5.0.dev0) (2.10)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (7.1.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (1.15.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.5.0.dev0) (1.0.1)\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.4.2\r\n",
      "    Uninstalling transformers-4.4.2:\r\n",
      "      Successfully uninstalled transformers-4.4.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "allennlp 2.2.0 requires transformers<4.5,>=4.1, but you have transformers 4.5.0.dev0 which is incompatible.\u001b[0m\r\n",
      "Successfully installed transformers-4.5.0.dev0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets --no-index --find-links=file:///kaggle/input/coleridge-packages/packages/datasets\n",
    "!pip install ../input/coleridge-packages/seqeval-1.2.2-py3-none-any.whl\n",
    "!pip install ../input/coleridge-packages/tokenizers-0.10.1-cp37-cp37m-manylinux1_x86_64.whl\n",
    "!pip install ../input/coleridge-packages/transformers-4.5.0.dev0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "speaking-welding",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-19T14:46:45.598919Z",
     "iopub.status.busy": "2021-06-19T14:46:45.597859Z",
     "iopub.status.idle": "2021-06-19T14:46:54.888860Z",
     "shell.execute_reply": "2021-06-19T14:46:54.887542Z",
     "shell.execute_reply.started": "2021-06-19T14:40:17.033993Z"
    },
    "papermill": {
     "duration": 9.320099,
     "end_time": "2021-06-19T14:46:54.889036",
     "exception": false,
     "start_time": "2021-06-19T14:46:45.568937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import glob\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling, \\\n",
    "AutoModelForMaskedLM, Trainer, TrainingArguments, pipeline\n",
    "\n",
    "sns.set()\n",
    "random.seed(123)\n",
    "np.random.seed(456)\n",
    "torch.manual_seed(2021)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sought-camera",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-19T14:46:54.934577Z",
     "iopub.status.busy": "2021-06-19T14:46:54.933906Z",
     "iopub.status.idle": "2021-06-19T14:46:54.937196Z",
     "shell.execute_reply": "2021-06-19T14:46:54.937652Z",
     "shell.execute_reply.started": "2021-06-19T14:41:40.590747Z"
    },
    "papermill": {
     "duration": 0.028445,
     "end_time": "2021-06-19T14:46:54.937835",
     "exception": false,
     "start_time": "2021-06-19T14:46:54.909390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PRETRAINED_PATH = '../input/coleridge-bert-mlmv4/mlm-model'\n",
    "TOKENIZER_PATH = '../input/coleridge-bert-mlmv4/model_tokenizer'\n",
    "\n",
    "MAX_LEN = 64\n",
    "OVERLAP = 20\n",
    "PREDICT_BATCH = 32\n",
    "\n",
    "PREDICT_BATCH = 32\n",
    "\n",
    "DATASET_SYMBOL = '$'\n",
    "NONDATA_SYMBOL = '#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "appreciated-template",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-19T14:46:54.984394Z",
     "iopub.status.busy": "2021-06-19T14:46:54.983666Z",
     "iopub.status.idle": "2021-06-19T14:46:54.999150Z",
     "shell.execute_reply": "2021-06-19T14:46:54.998421Z",
     "shell.execute_reply.started": "2021-06-19T14:40:26.415153Z"
    },
    "papermill": {
     "duration": 0.042432,
     "end_time": "2021-06-19T14:46:54.999315",
     "exception": false,
     "start_time": "2021-06-19T14:46:54.956883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_path = '../input/coleridgeinitiative-show-us-the-data/sample_submission.csv'\n",
    "submission = pd.read_csv(submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surface-campaign",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-19T14:46:55.054505Z",
     "iopub.status.busy": "2021-06-19T14:46:55.053730Z",
     "iopub.status.idle": "2021-06-19T14:46:55.086035Z",
     "shell.execute_reply": "2021-06-19T14:46:55.086683Z",
     "shell.execute_reply.started": "2021-06-19T14:40:30.197048Z"
    },
    "papermill": {
     "duration": 0.068248,
     "end_time": "2021-06-19T14:46:55.086931",
     "exception": false,
     "start_time": "2021-06-19T14:46:55.018683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_folder = '../input/coleridgeinitiative-show-us-the-data/test'\n",
    "paper_text = {}\n",
    "for p_id in submission['Id']:\n",
    "    with open(f'{test_folder}/{p_id}.json','r') as f:\n",
    "        text = json.load(f)\n",
    "        paper_text[p_id] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intensive-median",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-19T14:46:55.149195Z",
     "iopub.status.busy": "2021-06-19T14:46:55.148170Z",
     "iopub.status.idle": "2021-06-19T14:47:05.683523Z",
     "shell.execute_reply": "2021-06-19T14:47:05.682473Z",
     "shell.execute_reply.started": "2021-06-19T14:40:32.093480Z"
    },
    "papermill": {
     "duration": 10.565638,
     "end_time": "2021-06-19T14:47:05.683685",
     "exception": false,
     "start_time": "2021-06-19T14:46:55.118047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "model = AutoModelForMaskedLM.from_pretrained(PRETRAINED_PATH)\n",
    "\n",
    "mlm = pipeline(\n",
    "    'fill-mask', \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "mask = mlm.tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mexican-prevention",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-19T14:47:05.757880Z",
     "iopub.status.busy": "2021-06-19T14:47:05.755891Z",
     "iopub.status.idle": "2021-06-19T14:47:05.760857Z",
     "shell.execute_reply": "2021-06-19T14:47:05.760321Z",
     "shell.execute_reply.started": "2021-06-19T14:42:04.821252Z"
    },
    "papermill": {
     "duration": 0.057457,
     "end_time": "2021-06-19T14:47:05.760997",
     "exception": false,
     "start_time": "2021-06-19T14:47:05.703540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()\n",
    "\n",
    "def jaccard_similarity(s1, s2):\n",
    "    l1 = s1.split(\" \")\n",
    "    l2 = s2.split(\" \")    \n",
    "    intersection = len(list(set(l1).intersection(l2)))\n",
    "    union = (len(l1) + len(l2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "def clean_paper_sentence(s):\n",
    "    s = re.sub('[^A-Za-z0-9]+', ' ', str(s)).strip()\n",
    "    s = re.sub(' +', ' ', s)\n",
    "    return s\n",
    "\n",
    "def shorten_sentences(sentences):\n",
    "    short_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        if len(words) > MAX_LEN:\n",
    "            for p in range(0, len(words), MAX_LEN - OVERLAP):\n",
    "                short_sentences.append(' '.join(words[p:p+MAX_LEN]))\n",
    "        else:\n",
    "            short_sentences.append(sentence)\n",
    "    return short_sentences\n",
    "\n",
    "connection_tokens = {'s', 'of', 'and', 'in', 'on', 'for', 'data', 'dataset'}\n",
    "def find_mask_candidates(sentence):\n",
    "    def candidate_qualified(words):\n",
    "        while len(words) and words[0].lower() in connection_tokens:\n",
    "            words = words[1:]\n",
    "        while len(words) and words[-1].lower() in connection_tokens:\n",
    "            words = words[:-1]\n",
    "        \n",
    "        return len(words) >= 2\n",
    "    \n",
    "    candidates = []\n",
    "    \n",
    "    phrase_start, phrase_end = -1, -1\n",
    "    for id in range(1, len(sentence)):\n",
    "        word = sentence[id]\n",
    "        if word[0].isupper() or word in connection_tokens:\n",
    "            if phrase_start == -1:\n",
    "                phrase_start = phrase_end = id\n",
    "            else:\n",
    "                phrase_end = id\n",
    "        else:\n",
    "            if phrase_start != -1:\n",
    "                if candidate_qualified(sentence[phrase_start:phrase_end+1]):\n",
    "                    candidates.append((phrase_start, phrase_end))\n",
    "                phrase_start = phrase_end = -1\n",
    "    \n",
    "    if phrase_start != -1:\n",
    "        if candidate_qualified(sentence[phrase_start:phrase_end+1]):\n",
    "            candidates.append((phrase_start, phrase_end))\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stuffed-shadow",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-19T14:47:05.804702Z",
     "iopub.status.busy": "2021-06-19T14:47:05.804032Z",
     "iopub.status.idle": "2021-06-19T14:47:05.808954Z",
     "shell.execute_reply": "2021-06-19T14:47:05.808413Z",
     "shell.execute_reply.started": "2021-05-31T13:54:36.152581Z"
    },
    "papermill": {
     "duration": 0.028842,
     "end_time": "2021-06-19T14:47:05.809092",
     "exception": false,
     "start_time": "2021-06-19T14:47:05.780250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_test_data = []\n",
    "\n",
    "# for paper_id in submission['Id']:\n",
    "#     paper = paper_text[paper_id]\n",
    "    \n",
    "# #     sentences = set([clean_paper_sentence(sentence) for section in paper \n",
    "# #                      for sentence in section['text'].split('.')\n",
    "# #                     ])\n",
    "# #     sentences = shorten_sentences(sentences)\n",
    "# #     sentences = [sentence for sentence in sentences if len(sentence) > 10]\n",
    "# #     sentences = [sentence for sentence in sentences if any(word in sentence.lower() for word in ['data', 'study'])]\n",
    "# #     sentences = [sentence.split() for sentence in sentences]\n",
    "\n",
    "#     content = '. '.join(section['text'] for section in paper)\n",
    "#     sentences = set([clean_paper_sentence(sentence) for sentence in content.split('.')])\n",
    "#     sentences = shorten_sentences(sentences) # make sentences short\n",
    "#     sentences = [sentence for sentence in sentences if len(sentence) > 10] # only accept sentences with length > 10 chars\n",
    "#     sentences = [sentence.split() for sentence in sentences]\n",
    "    \n",
    "#     # mask\n",
    "#     test_data = []\n",
    "#     for sentence in sentences:\n",
    "#         for phrase_start, phrase_end in find_mask_candidates(sentence):\n",
    "#             dt_point = sentence[:phrase_start] + [mask] + sentence[phrase_end+1:]\n",
    "#             test_data.append((' '.join(dt_point), ' '.join(sentence[phrase_start:phrase_end+1]))) # (masked text, phrase)\n",
    "    \n",
    "#     all_test_data.append(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "published-anthony",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-19T14:47:05.861897Z",
     "iopub.status.busy": "2021-06-19T14:47:05.856594Z",
     "iopub.status.idle": "2021-06-19T14:47:05.955916Z",
     "shell.execute_reply": "2021-06-19T14:47:05.956436Z",
     "shell.execute_reply.started": "2021-06-19T14:42:11.247912Z"
    },
    "papermill": {
     "duration": 0.128224,
     "end_time": "2021-06-19T14:47:05.956621",
     "exception": false,
     "start_time": "2021-06-19T14:47:05.828397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_test_data = []\n",
    "\n",
    "for paper_id in submission['Id']:\n",
    "    paper = paper_text[paper_id]\n",
    "    \n",
    "#     sentences = set([clean_paper_sentence(sentence) for section in paper \n",
    "#                      for sentence in section['text'].split('.')\n",
    "#                     ])\n",
    "#     sentences = shorten_sentences(sentences)\n",
    "#     sentences = [sentence for sentence in sentences if len(sentence) > 10]\n",
    "#     sentences = [sentence for sentence in sentences if any(word in sentence.lower() for word in ['data', 'study'])]\n",
    "#     sentences = [sentence.split() for sentence in sentences]\n",
    "\n",
    "    content = '. '.join(section['text'] for section in paper)\n",
    "    sentences = set([clean_paper_sentence(sentence) for sentence in content.split('.')])\n",
    "    sentences = shorten_sentences(sentences) # make sentences short\n",
    "    sentences = [sentence for sentence in sentences if len(sentence) > 10] # only accept sentences with length > 10 chars\n",
    "    sentences = [sentence.split() for sentence in sentences]\n",
    "    \n",
    "    # mask\n",
    "    test_data = []\n",
    "    for sentence in sentences:\n",
    "        for phrase_start, phrase_end in find_mask_candidates(sentence):\n",
    "            dt_point = sentence[:phrase_start] + [mask] + sentence[phrase_end+1:]\n",
    "            test_data.append((' '.join(dt_point), ' '.join(sentence[phrase_start:phrase_end+1]))) # (masked text, phrase)\n",
    "    \n",
    "    all_test_data.append(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "offensive-suggestion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-19T14:47:05.999167Z",
     "iopub.status.busy": "2021-06-19T14:47:05.998465Z",
     "iopub.status.idle": "2021-06-19T14:47:06.002576Z",
     "shell.execute_reply": "2021-06-19T14:47:06.003107Z",
     "shell.execute_reply.started": "2021-05-31T13:54:40.723213Z"
    },
    "papermill": {
     "duration": 0.027313,
     "end_time": "2021-06-19T14:47:06.003299",
     "exception": false,
     "start_time": "2021-06-19T14:47:05.975986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_test_data = []\n",
    "\n",
    "# # pbar = tqdm(total = len(sample_submission))\n",
    "# for paper_id in sample_submission['Id']:\n",
    "#     # load paper\n",
    "#     paper = papers[paper_id]\n",
    "    \n",
    "#     # extract sentences\n",
    "#     sentences = set([clean_paper_sentence(sentence) for section in paper \n",
    "#                      for sentence in section['text'].split('.')\n",
    "#                     ])\n",
    "#     sentences = shorten_sentences(sentences) # make sentences short\n",
    "#     sentences = [sentence for sentence in sentences if len(sentence) > 10] # only accept sentences with length > 10 chars\n",
    "#     sentences = [sentence for sentence in sentences if any(word in sentence.lower() for word in ['data', 'study'])]\n",
    "#     sentences = [sentence.split() for sentence in sentences] # sentence = list of words\n",
    "    \n",
    "#     # mask\n",
    "#     test_data = []\n",
    "#     for sentence in sentences:\n",
    "#         for phrase_start, phrase_end in find_mask_candidates(sentence):\n",
    "#             dt_point = sentence[:phrase_start] + [mask] + sentence[phrase_end+1:]\n",
    "#             test_data.append((' '.join(dt_point), ' '.join(sentence[phrase_start:phrase_end+1]))) # (masked text, phrase)\n",
    "    \n",
    "#     all_test_data.append(test_data)\n",
    "    \n",
    "#     # process bar\n",
    "# #     pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-saskatchewan",
   "metadata": {
    "papermill": {
     "duration": 0.022951,
     "end_time": "2021-06-19T14:47:06.046007",
     "exception": false,
     "start_time": "2021-06-19T14:47:06.023056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "opposed-farmer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-19T14:47:06.095128Z",
     "iopub.status.busy": "2021-06-19T14:47:06.094514Z",
     "iopub.status.idle": "2021-06-19T14:49:10.382153Z",
     "shell.execute_reply": "2021-06-19T14:49:10.381428Z",
     "shell.execute_reply.started": "2021-06-19T14:42:15.641114Z"
    },
    "papermill": {
     "duration": 124.31295,
     "end_time": "2021-06-19T14:49:10.382364",
     "exception": false,
     "start_time": "2021-06-19T14:47:06.069414",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:04<00:00, 30.26s/it]"
     ]
    }
   ],
   "source": [
    "pred_labels = []\n",
    "\n",
    "pbar = tqdm(total = len(all_test_data))\n",
    "for test_data in all_test_data:\n",
    "    pred_bag = set()\n",
    "    \n",
    "    if len(test_data):\n",
    "        texts, phrases = list(zip(*test_data))\n",
    "        mlm_pred = []\n",
    "        for p_id in range(0, len(texts), PREDICT_BATCH):\n",
    "            batch_texts = texts[p_id:p_id+PREDICT_BATCH]\n",
    "            batch_pred = mlm(list(batch_texts), targets=[f' {DATASET_SYMBOL}', f' {NONDATA_SYMBOL}'])\n",
    "            \n",
    "            if len(batch_texts) == 1:\n",
    "                batch_pred = [batch_pred]\n",
    "            \n",
    "            mlm_pred.extend(batch_pred)\n",
    "        \n",
    "        for (result1, result2), phrase in zip(mlm_pred, phrases):\n",
    "            if (result1['score'] > result2['score']*1.5 and result1['token_str'] == DATASET_SYMBOL) or\\\n",
    "               (result2['score'] > result1['score']*1.5 and result2['token_str'] == NONDATA_SYMBOL):\n",
    "                pred_bag.add(clean_text(phrase))\n",
    "    \n",
    "    # filter labels by jaccard score \n",
    "    filtered_labels = []\n",
    "    \n",
    "    for label in sorted(pred_bag, key=len, reverse=True):\n",
    "        if len(filtered_labels) == 0 or all(jaccard_similarity(label, got_label) < 0.75 for got_label in filtered_labels):\n",
    "            filtered_labels.append(label)\n",
    "            \n",
    "    pred_labels.append('|'.join(filtered_labels))\n",
    "    pbar.update(1)\n",
    "\n",
    "submission['PredictionString'] = pred_labels\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "empty-collector",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-19T14:49:10.435589Z",
     "iopub.status.busy": "2021-06-19T14:49:10.434900Z",
     "iopub.status.idle": "2021-06-19T14:49:10.438921Z",
     "shell.execute_reply": "2021-06-19T14:49:10.438260Z",
     "shell.execute_reply.started": "2021-06-19T14:44:21.694420Z"
    },
    "papermill": {
     "duration": 0.034849,
     "end_time": "2021-06-19T14:49:10.439085",
     "exception": false,
     "start_time": "2021-06-19T14:49:10.404236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    cohorts for heart and aging research in genomi...\n",
       "1    center for education statistics institute of e...\n",
       "2    dataset data management in arcgis|s office for...\n",
       "3                           food access research atlas\n",
       "Name: PredictionString, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['PredictionString'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 244.688075,
   "end_time": "2021-06-19T14:49:11.976164",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-19T14:45:07.288089",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
